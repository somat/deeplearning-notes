# Papers Mentioned in Sequence Model Course by Deeplearning.ai

## Week 1

### GRU

* [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches](https://arxiv.org/abs/1409.1259)
* [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/abs/1412.3555)

### LSTM

* [LONG SHORT-TERM MEMORY](http://www.bioinf.jku.at/publications/older/2604.pdf)

## Week 2

### Skip-Grams, Hierarchical Softmax

* [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)

### Negative Sampling

* [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)

### GloVe

* [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)

### Debiasing Word Embeddings

* [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://pdfs.semanticscholar.org/2744/59c52103f9b7880d0697aa28755ac3366987.pdf)

## Week 3

### Sequence to Sequence Model

* [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)
* [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)

### Image Captioning

* [Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)](https://arxiv.org/abs/1412.6632)
* [Show and Tell: A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555)
* [Deep Visual-Semantic Alignments for Generating Image Descriptions](https://cs.stanford.edu/people/karpathy/cvpr2015.pdf)

### BLEU Score

* [BLEU: a Method for Automatic Evaluation of Machine Translation](https://www.aclweb.org/anthology/P02-1040.pdf)

### Attention Model Intuition

* [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
* [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044)

### Speech Recognition

* [Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks](https://www.cs.toronto.edu/~graves/icml_2006.pdf)

### Notes

Credit: https://iitrsamrat.github.io/deeplearning.ai.sequence-model-papers/

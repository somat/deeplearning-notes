# Papers Mentioned in Sequence Model Course by Deeplearning.ai

## Week 1

### GRU

* [On the Properties of Neural Machine Translation: Encoder-Decoder Approaches](https://arxiv.org/abs/1409.1259)
* [Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/abs/1412.3555)

### LSTM

* [LONG SHORT-TERM MEMORY](http://www.bioinf.jku.at/publications/older/2604.pdf)

## Week 2

### Skip-Grams, Hierarchical Softmax

* [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781)

### Negative Sampling

* [Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546)

### GloVe

* [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)

### Debiasing Word Embeddings

* [Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings](https://pdfs.semanticscholar.org/2744/59c52103f9b7880d0697aa28755ac3366987.pdf)


Credit: https://iitrsamrat.github.io/deeplearning.ai.sequence-model-papers/
